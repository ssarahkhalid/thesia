# config.yaml

paths:
  models_dir: "models"
  data_dir: "data"
  templates_dir: "templates"
  vectorstore_dir: "data/vectorstore"

model:
  llm:
    repo_id: "TheBloke/Llama-2-7B-Chat-GGUF"
    filename: "llama-2-7b-chat.Q4_K_M.gguf"
    n_ctx: 2048
    n_gpu_layers: 0
    temperature: 0.7
    max_tokens: 2000
    top_p: 0.95
  
  embeddings:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    cache_dir: "models/embeddings"

rag:
  chunk_size: 1000
  chunk_overlap: 200
  k_retrieval: 4